#!/usr/bin/env python3
"""
Aç±»è®­ç»ƒæ•°æ®æ„å»ºï¼šé£Ÿè°±é€‰æ‹©ä¸æ’åºï¼ˆä¿®å¤ç‰ˆï¼‰
- ä¿®å¤ï¼šrecipe_id ç±»å‹ç»Ÿä¸€åå†åˆå¹¶
- 520Kè¡Œ â†’ 520Kè¡Œï¼ˆæ— æŸå¤±ï¼‰
"""

import pandas as pd
import numpy as np
import json
import graph_tool.all as gt
from collections import defaultdict
from tqdm import tqdm
import random
from typing import List, Dict, Tuple
import re

class TaskADatasetBuilder:
    """Aç±»æ•°æ®é›†æ„å»ºå™¨ï¼ˆä¿®å¤ç‰ˆï¼‰"""

    def __init__(self, kg_path: str, recipe_basic_path: str,
                 recipe_nutrition_path: str, user_profile_path: str):
        """åˆå§‹åŒ–"""
        print("="*80)
        print("Aç±»æ•°æ®é›†æ„å»ºå™¨ - ä¿®å¤ç‰ˆ")
        print("="*80)

        # åŠ è½½KGè§„åˆ™
        self._load_kg_rules(kg_path)

        # åŠ è½½é£Ÿè°±æ•°æ®
        self._load_recipes(recipe_basic_path, recipe_nutrition_path)

        # åŠ è½½ç”¨æˆ·ç”»åƒ
        self._load_user_profiles(user_profile_path)

    def _load_kg_rules(self, kg_path: str):
        """ä»KGä¸­åŠ è½½è§„åˆ™"""
        print(f"\n[1/3] åŠ è½½KGè§„åˆ™: {kg_path}")
        graph = gt.load_graph(kg_path)

        node_id = graph.vertex_properties["node_id"]
        edge_type = graph.edge_properties["edge_type"]
        pmi_score = graph.edge_properties.get("pmi_score")
        cooccurrence_count = graph.edge_properties.get("cooccurrence_count")
        confidence = graph.edge_properties.get("confidence")
        synergy_score = graph.edge_properties.get("synergy_score")
        synergy_reason = graph.edge_properties.get("synergy_reason")

        # æ„å»ºè§„åˆ™ç´¢å¼•
        self.cooccurrence_rules = {}
        self.complementarity_rules = {}
        self.ingredient_tags = defaultdict(list)

        for e in graph.edges():
            etype = edge_type[e]
            src = node_id[e.source()]
            tgt = node_id[e.target()]

            if etype == "ingredient_cooccurs":
                self.cooccurrence_rules[(src, tgt)] = {
                    'pmi': float(pmi_score[e]),
                    'count': int(cooccurrence_count[e]),
                    'confidence': float(confidence[e])
                }

            elif etype == "ingredient_complements":
                self.complementarity_rules[(src, tgt)] = {
                    'score': float(synergy_score[e]),
                    'reason': str(synergy_reason[e])
                }

            elif etype == "ingredient_has_tag":
                self.ingredient_tags[src].append(tgt)

        print(f"  âœ“ å…±ç°è§„åˆ™: {len(self.cooccurrence_rules):,}")
        print(f"  âœ“ äº’è¡¥è§„åˆ™: {len(self.complementarity_rules):,}")
        print(f"  âœ“ è¥å…»æ ‡ç­¾: {len(self.ingredient_tags):,} ä¸ªé£Ÿæ")

    def _parse_r_vector(self, r_str):
        """è§£æRçš„c()å‘é‡"""
        if pd.isna(r_str) or r_str == 'NA':
            return []
        r_str = str(r_str).strip()
        if r_str.startswith('c(') and r_str.endswith(')'):
            r_str = r_str[2:-1]
        items = re.findall(r'"([^"]*)"', r_str)
        return items

    def _load_recipes(self, basic_path: str, nutrition_path: str):
        """åŠ è½½é£Ÿè°±æ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼šç»Ÿä¸€ç±»å‹ååˆå¹¶ï¼‰"""
        print(f"\n[2/3] åŠ è½½é£Ÿè°±æ•°æ®")

        # åŠ è½½åŸºç¡€ä¿¡æ¯
        print(f"  åŠ è½½åŸºç¡€ä¿¡æ¯: {basic_path}")
        df_basic = pd.read_csv(basic_path, encoding='latin-1', low_memory=False)
        print(f"    åŸå§‹è¡Œæ•°: {len(df_basic):,}")
        print(f"    recipe_id ç±»å‹: {df_basic['recipe_id'].dtype}")

        # åŠ è½½è¥å…»æ•°æ®
        print(f"  åŠ è½½è¥å…»æ•°æ®: {nutrition_path}")
        df_nutrition = pd.read_csv(nutrition_path)
        print(f"    åŸå§‹è¡Œæ•°: {len(df_nutrition):,}")
        print(f"    recipe_id ç±»å‹: {df_nutrition['recipe_id'].dtype}")

        # â­ å…³é”®ä¿®å¤ï¼šç»Ÿä¸€ recipe_id ç±»å‹ä¸ºæ•´æ•°
        print(f"\n  ç»Ÿä¸€ recipe_id ç±»å‹...")
        df_basic['recipe_id'] = pd.to_numeric(df_basic['recipe_id'], errors='coerce').astype('Int64')
        df_nutrition['recipe_id'] = pd.to_numeric(df_nutrition['recipe_id'], errors='coerce').astype('Int64')

        # åˆ é™¤è½¬æ¢å¤±è´¥çš„è¡Œï¼ˆNaNï¼‰
        basic_before = len(df_basic)
        df_basic = df_basic.dropna(subset=['recipe_id'])
        print(f"    åŸºç¡€æ•°æ®åˆ é™¤æ— æ•ˆ recipe_id: {basic_before - len(df_basic)} è¡Œ")

        nutrition_before = len(df_nutrition)
        df_nutrition = df_nutrition.dropna(subset=['recipe_id'])
        print(f"    è¥å…»æ•°æ®åˆ é™¤æ— æ•ˆ recipe_id: {nutrition_before - len(df_nutrition)} è¡Œ")

        # æ£€æŸ¥é‡å¤
        basic_dup = df_basic['recipe_id'].duplicated().sum()
        nutrition_dup = df_nutrition['recipe_id'].duplicated().sum()
        print(f"    åŸºç¡€æ•°æ®é‡å¤ recipe_id: {basic_dup}")
        print(f"    è¥å…»æ•°æ®é‡å¤ recipe_id: {nutrition_dup}")

        if basic_dup > 0:
            df_basic = df_basic.drop_duplicates(subset=['recipe_id'], keep='first')
            print(f"    å·²åˆ é™¤åŸºç¡€æ•°æ®é‡å¤è¡Œ")

        if nutrition_dup > 0:
            df_nutrition = df_nutrition.drop_duplicates(subset=['recipe_id'], keep='first')
            print(f"    å·²åˆ é™¤è¥å…»æ•°æ®é‡å¤è¡Œ")

        # æ£€æŸ¥äº¤é›†
        basic_ids = set(df_basic['recipe_id'].dropna())
        nutrition_ids = set(df_nutrition['recipe_id'].dropna())
        intersection = basic_ids & nutrition_ids
        print(f"\n  recipe_id äº¤é›†åˆ†æ:")
        print(f"    åŸºç¡€æ•°æ®å”¯ä¸€ID: {len(basic_ids):,}")
        print(f"    è¥å…»æ•°æ®å”¯ä¸€ID: {len(nutrition_ids):,}")
        print(f"    äº¤é›†IDæ•°: {len(intersection):,}")
        print(f"    åŸºç¡€æ•°æ®ç‹¬æœ‰: {len(basic_ids - nutrition_ids):,}")
        print(f"    è¥å…»æ•°æ®ç‹¬æœ‰: {len(nutrition_ids - basic_ids):,}")

        # åˆå¹¶ï¼ˆinner join åªä¿ç•™äº¤é›†ï¼‰
        print(f"\n  åˆå¹¶æ•°æ®...")
        self.recipes_df = df_basic.merge(df_nutrition, on='recipe_id', how='inner')
        print(f"    âœ“ åˆå¹¶å: {len(self.recipes_df):,} è¡Œ")

        # æ„å»ºå¿«é€ŸæŸ¥è¯¢ç´¢å¼•
        print(f"\n  æ„å»ºé£Ÿè°±ç´¢å¼•...")
        self.recipe_dict = {}
        skipped_count = 0

        for _, row in tqdm(self.recipes_df.iterrows(), desc="    å¤„ç†ä¸­", total=len(self.recipes_df)):
            recipe_id = str(int(row['recipe_id']))  # è½¬ä¸ºå­—ç¬¦ä¸²ä½œä¸ºkey
            ingredients = self._parse_r_vector(row.get('RecipeIngredientParts', ''))

            # è·³è¿‡ç©ºé£Ÿæçš„é£Ÿè°±
            if not ingredients or len(ingredients) == 0:
                skipped_count += 1
                continue

            self.recipe_dict[recipe_id] = {
                'name': row.get('recipe_name', row.get('Name', f'Recipe_{recipe_id}')),
                'ingredients': ingredients,
                'nutrition': {
                    'calories': float(row.get('Calories_PerServing_kcal', 0)) if pd.notna(row.get('Calories_PerServing_kcal')) else 0.0,
                    'protein': float(row.get('Protein_PerServing_g', 0)) if pd.notna(row.get('Protein_PerServing_g')) else 0.0,
                    'fat': float(row.get('Fat_PerServing_g', 0)) if pd.notna(row.get('Fat_PerServing_g')) else 0.0,
                    'carbohydrates': float(row.get('Carbohydrates_PerServing_g', 0)) if pd.notna(row.get('Carbohydrates_PerServing_g')) else 0.0,
                    'fiber': float(row.get('Fiber_PerServing_g', 0)) if pd.notna(row.get('Fiber_PerServing_g')) else 0.0,
                    'sugars': float(row.get('Sugars_PerServing_g', 0)) if pd.notna(row.get('Sugars_PerServing_g')) else 0.0,
                    'saturated_fat': float(row.get('SaturatedFat_PerServing_g', 0)) if pd.notna(row.get('SaturatedFat_PerServing_g')) else 0.0,
                    'sodium': float(row.get('Sodium_PerServing_mg', 0)) if pd.notna(row.get('Sodium_PerServing_mg')) else 0.0,
                }
            }

        self.all_recipe_ids = list(self.recipe_dict.keys())
        print(f"    âœ“ æœ‰æ•ˆé£Ÿè°±: {len(self.recipe_dict):,} ä¸ª")
        if skipped_count > 0:
            print(f"    âš  è·³è¿‡ç©ºé£Ÿæ: {skipped_count:,} ä¸ª")

    def _load_user_profiles(self, profile_path: str):
        """åŠ è½½ç”¨æˆ·ç”»åƒ"""
        print(f"\n[3/3] åŠ è½½ç”¨æˆ·ç”»åƒ: {profile_path}")

        self.users = []
        with open(profile_path, 'r', encoding='utf-8') as f:
            for line in f:
                self.users.append(json.loads(line))

        print(f"  âœ“ åŠ è½½ç”¨æˆ·: {len(self.users):,}")

    # ==================== æ‰“åˆ†å‡½æ•° ====================

    def score_nutrition_match(self, recipe_nutrition: Dict, user_targets: Dict) -> float:
        """è¥å…»ç›®æ ‡åŒ¹é…åº¦ (0-1)"""
        if not user_targets:
            return 0.5

        scores = []

        # èƒ½é‡ç›®æ ‡
        energy_target = user_targets.get('energy_kcal_target')
        if energy_target and recipe_nutrition.get('calories', 0) > 0:
            ratio = recipe_nutrition['calories'] / energy_target
            if 0.8 <= ratio <= 1.2:
                scores.append(1.0)
            elif 0.6 <= ratio <= 1.4:
                scores.append(0.7)
            else:
                scores.append(0.3)

        # AMDRä¸‰å¤§è¥å…»ç´ 
        amdr = user_targets.get('amdr', {})
        if amdr:
            total_energy = (
                recipe_nutrition.get('protein', 0) * 4 +
                recipe_nutrition.get('fat', 0) * 9 +
                recipe_nutrition.get('carbohydrates', 0) * 4
            )
            if total_energy > 0:
                for key, nutrient in [('carb', 'carbohydrates'), ('protein', 'protein'), ('fat', 'fat')]:
                    if key in amdr:
                        kcal_per_g = 4 if key != 'fat' else 9
                        actual_pct = (recipe_nutrition.get(nutrient, 0) * kcal_per_g / total_energy) * 100
                        target_pct = amdr[key].get('target_pct', 0)

                        if target_pct > 0:
                            diff = abs(actual_pct - target_pct)
                            if diff <= 5:
                                scores.append(1.0)
                            elif diff <= 10:
                                scores.append(0.7)
                            else:
                                scores.append(0.4)

        # é’ æœ€å¤§å€¼
        sodium_max = user_targets.get('sodium_mg_max')
        if sodium_max and recipe_nutrition.get('sodium', 0) > 0:
            if recipe_nutrition['sodium'] <= sodium_max:
                scores.append(1.0)
            elif recipe_nutrition['sodium'] <= sodium_max * 1.2:
                scores.append(0.6)
            else:
                scores.append(0.2)

        # çº¤ç»´æœ€å°å€¼
        fiber_min = user_targets.get('fiber_g_min')
        if fiber_min and recipe_nutrition.get('fiber', 0) > 0:
            if recipe_nutrition['fiber'] >= fiber_min:
                scores.append(1.0)
            elif recipe_nutrition['fiber'] >= fiber_min * 0.8:
                scores.append(0.7)
            else:
                scores.append(0.4)

        return np.mean(scores) if scores else 0.5

    def score_ingredient_preference(self, recipe_ingredients: List[str],
                                   liked: List[str], disliked: List[str]) -> float:
        """é£Ÿæåå¥½åŒ¹é…åº¦ (0-1)"""
        if not liked and not disliked:
            return 0.5

        recipe_set = set(recipe_ingredients)
        disliked_count = len(recipe_set & set(disliked))
        liked_count = len(recipe_set & set(liked))

        if disliked_count > 0:
            return 0.1

        if liked_count > 0:
            return min(0.7 + liked_count * 0.1, 1.0)

        return 0.5

    def score_cooccurrence(self, ingredients: List[str]) -> float:
        """é£Ÿæå…±ç°åˆ†æ•° (0-1)"""
        if len(ingredients) < 2:
            return 0.0

        total_pmi = 0.0
        pair_count = 0

        for i in range(len(ingredients)):
            for j in range(i+1, len(ingredients)):
                rule = self.cooccurrence_rules.get((ingredients[i], ingredients[j])) or \
                       self.cooccurrence_rules.get((ingredients[j], ingredients[i]))

                if rule:
                    normalized_pmi = min(rule['pmi'] / 10.0, 1.0)
                    total_pmi += normalized_pmi
                    pair_count += 1

        return total_pmi / pair_count if pair_count > 0 else 0.0

    def score_complementarity(self, ingredients: List[str]) -> float:
        """è¥å…»äº’è¡¥åˆ†æ•° (0-1)"""
        if len(ingredients) < 2:
            return 0.0

        total_synergy = 0.0
        pair_count = 0

        for i in range(len(ingredients)):
            for j in range(i+1, len(ingredients)):
                rule = self.complementarity_rules.get((ingredients[i], ingredients[j])) or \
                       self.complementarity_rules.get((ingredients[j], ingredients[i]))

                if rule:
                    total_synergy += rule['score']
                    pair_count += 1

        return total_synergy / pair_count if pair_count > 0 else 0.0

    def score_nutrition_balance(self, ingredients: List[str]) -> float:
        """è¥å…»å¹³è¡¡åˆ†æ•° (0-1)"""
        all_tags = []
        for ing in ingredients:
            all_tags.extend(self.ingredient_tags.get(ing, []))

        if not all_tags:
            return 0.5

        tag_counts = defaultdict(int)
        for tag in all_tags:
            tag_counts[tag] += 1

        total = len(all_tags)
        entropy = 0.0
        for count in tag_counts.values():
            p = count / total
            entropy -= p * np.log2(p)

        max_entropy = np.log2(len(tag_counts)) if len(tag_counts) > 1 else 1.0
        diversity = entropy / max_entropy if max_entropy > 0 else 0.0

        positive_tags = ['high_protein', 'high_fiber', 'high_vitamin_c',
                        'high_calcium', 'high_iron', 'low_sodium', 'low_fat']
        positive_count = sum(1 for tag in all_tags if tag in positive_tags)
        positive_ratio = positive_count / len(all_tags)

        return 0.5 * diversity + 0.5 * positive_ratio

    def score_recipe(self, recipe_id: str, user: Dict) -> Tuple[float, Dict]:
        """ç»¼åˆæ‰“åˆ†"""
        weights = {
            'nutrition': 0.3,
            'preference': 0.2,
            'cooccurrence': 0.2,
            'complementarity': 0.2,
            'balance': 0.1
        }

        recipe = self.recipe_dict.get(recipe_id)
        if not recipe:
            return 0.0, {}

        liked_ings = [item['name'] for item in user.get('liked_ingredients', [])]
        disliked_ings = [item['name'] for item in user.get('disliked_ingredients', [])]
        nutrition_targets = user.get('nutrition_targets', {})

        nutrition_score = self.score_nutrition_match(recipe['nutrition'], nutrition_targets)
        preference_score = self.score_ingredient_preference(recipe['ingredients'],
                                                            liked_ings, disliked_ings)
        cooccurrence_score = self.score_cooccurrence(recipe['ingredients'])
        complementarity_score = self.score_complementarity(recipe['ingredients'])
        balance_score = self.score_nutrition_balance(recipe['ingredients'])

        total_score = (
            weights['nutrition'] * nutrition_score +
            weights['preference'] * preference_score +
            weights['cooccurrence'] * cooccurrence_score +
            weights['complementarity'] * complementarity_score +
            weights['balance'] * balance_score
        )

        breakdown = {
            'nutrition': round(nutrition_score, 3),
            'preference': round(preference_score, 3),
            'cooccurrence': round(cooccurrence_score, 3),
            'complementarity': round(complementarity_score, 3),
            'balance': round(balance_score, 3)
        }

        return round(total_score, 3), breakdown

    # ==================== æ ·æœ¬ç”Ÿæˆ ====================

    def generate_samples_for_user(self, user: Dict) -> List[Dict]:
        """ä¸ºå•ä¸ªç”¨æˆ·ç”Ÿæˆè®­ç»ƒæ ·æœ¬"""
        user_id = user['user_id']

        # éšæœºé‡‡æ ·1500å€™é€‰
        sampled_ids = random.sample(self.all_recipe_ids, min(1500, len(self.all_recipe_ids)))

        scored_recipes = []
        for recipe_id in sampled_ids:
            score, breakdown = self.score_recipe(recipe_id, user)
            scored_recipes.append((recipe_id, score, breakdown))

        scored_recipes.sort(key=lambda x: x[1], reverse=True)

        samples = []

        # æ­£æ ·æœ¬ï¼šTop-3
        for recipe_id, score, breakdown in scored_recipes[:3]:
            samples.append({
                'user_id': user_id,
                'recipe_id': recipe_id,
                'recipe_name': self.recipe_dict[recipe_id]['name'],
                'ingredients': self.recipe_dict[recipe_id]['ingredients'],
                'nutrition': self.recipe_dict[recipe_id]['nutrition'],
                'label': 1,
                'score': score,
                'score_breakdown': breakdown,
                'sample_type': 'positive'
            })

        # éšæœºè´Ÿæ ·æœ¬ï¼š5ä¸ª
        low_score_pool = [r for r in scored_recipes if r[1] < 0.4]
        neg_samples = random.sample(low_score_pool, min(5, len(low_score_pool)))

        for recipe_id, score, breakdown in neg_samples:
            samples.append({
                'user_id': user_id,
                'recipe_id': recipe_id,
                'recipe_name': self.recipe_dict[recipe_id]['name'],
                'ingredients': self.recipe_dict[recipe_id]['ingredients'],
                'nutrition': self.recipe_dict[recipe_id]['nutrition'],
                'label': 0,
                'score': score,
                'score_breakdown': breakdown,
                'sample_type': 'random_negative'
            })

        # ç¡¬è´Ÿæ ·æœ¬ï¼š2ä¸ª
        hard_neg_pool = [r for r in scored_recipes if 0.4 <= r[1] < 0.6]
        hard_neg_samples = random.sample(hard_neg_pool, min(2, len(hard_neg_pool)))

        for recipe_id, score, breakdown in hard_neg_samples:
            samples.append({
                'user_id': user_id,
                'recipe_id': recipe_id,
                'recipe_name': self.recipe_dict[recipe_id]['name'],
                'ingredients': self.recipe_dict[recipe_id]['ingredients'],
                'nutrition': self.recipe_dict[recipe_id]['nutrition'],
                'label': 0,
                'score': score,
                'score_breakdown': breakdown,
                'sample_type': 'hard_negative'
            })

        return samples

    def build_dataset(self, users_list: List[Dict], output_path: str):
        """æ„å»ºæ•°æ®é›†"""
        all_samples = []
        for user in tqdm(users_list, desc=f"ç”Ÿæˆæ ·æœ¬"):
            samples = self.generate_samples_for_user(user)
            all_samples.extend(samples)

        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            for sample in all_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')

        print(f"âœ“ {output_path}: {len(all_samples):,} æ ·æœ¬")
        print(f"  æ­£æ ·æœ¬: {sum(1 for s in all_samples if s['label'] == 1):,}")
        print(f"  è´Ÿæ ·æœ¬: {sum(1 for s in all_samples if s['label'] == 0):,}")

        return len(all_samples)


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    np.random.seed(42)

    # æ„å»ºæ•°æ®é›†
    builder = TaskADatasetBuilder(
        kg_path="work/recipebench/kg/nutriplan_kg3.graphml",
        recipe_basic_path="work/recipebench/data/raw/foodcom/recipes(3column).csv",
        recipe_nutrition_path="work/recipebench/data/4out/recipe_nutrition_foodcom.csv",
        user_profile_path="work/recipebench/data/8step_profile/cleaned_user_profile.jsonl"
    )

    # éšæœºæ‰“ä¹±ç”¨æˆ·
    random.shuffle(builder.users)

    # åˆ’åˆ†ç”¨æˆ·
    train_users = builder.users[:10000]
    val_users = builder.users[10000:12000]
    test_users = builder.users[12000:14000]

    print(f"\n{'='*80}")
    print("æ•°æ®é›†é…ç½®")
    print(f"{'='*80}")
    print(f"è®­ç»ƒé›†: 10,000 ç”¨æˆ·")
    print(f"éªŒè¯é›†: 2,000 ç”¨æˆ·")
    print(f"æµ‹è¯•é›†: 2,000 ç”¨æˆ·")
    print(f"æ¯ç”¨æˆ·: 10 æ ·æœ¬ (3æ­£+5è´Ÿ+2ç¡¬è´Ÿ)")

    # ç”Ÿæˆè®­ç»ƒé›†
    print(f"\n{'='*80}")
    print("ç”Ÿæˆè®­ç»ƒé›†")
    print(f"{'='*80}")
    builder.build_dataset(train_users, "work/recipebench/data/10large_scale_datasets/task_a_train_new.jsonl")

    # ç”ŸæˆéªŒè¯é›†
    print(f"\n{'='*80}")
    print("ç”ŸæˆéªŒè¯é›†")
    print(f"{'='*80}")
    builder.build_dataset(val_users, "work/recipebench/data/10large_scale_datasets/task_a_val_new.jsonl")

    # ç”Ÿæˆæµ‹è¯•é›†
    print(f"\n{'='*80}")
    print("ç”Ÿæˆæµ‹è¯•é›†")
    print(f"{'='*80}")
    builder.build_dataset(test_users, "work/recipebench/data/10large_scale_datasets/task_a_test_new.jsonl")

    print(f"\n{'='*80}")
    print("ğŸ‰ Aç±»æ•°æ®é›†æ„å»ºå®Œæˆï¼")
    print(f"{'='*80}")
    print("è¾“å‡ºæ–‡ä»¶ï¼š")
    print("  - work/recipebench/data/10large_scale_datasets/task_a_train_new.jsonl  (~10ä¸‡æ ·æœ¬)")
    print("  - work/recipebench/data/10large_scale_datasets/task_a_val_new.jsonl    (~2ä¸‡æ ·æœ¬)")
    print("  - work/recipebench/data/10large_scale_datasets/task_a_test_new.jsonl   (~2ä¸‡æ ·æœ¬)")
