#!/bin/bash
# å®Œæ•´è¯„ä¼°æµç¨‹ï¼šç”Ÿæˆé¢„æµ‹ â†’ è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ â†’ ç”Ÿæˆè®ºæ–‡è¡¨æ ¼
# ç”¨æ³•: bash full_evaluation_pipeline.sh <model_path> <model_name> <seed>

set -e

MODEL_PATH=$1
MODEL_NAME=$2
SEED=$3

if [ -z "$MODEL_PATH" ] || [ -z "$MODEL_NAME" ] || [ -z "$SEED" ]; then
    echo "ç”¨æ³•: bash full_evaluation_pipeline.sh <model_path> <model_name> <seed>"
    echo "ç¤ºä¾‹: bash full_evaluation_pipeline.sh ~/work/nutriplan_models_backup/rq1_TinyLlama_seed42/best_model TinyLlama 42"
    exit 1
fi

# é…ç½®
DATA_DIR="${HOME}/work/recipebench/data/10large_scale_datasets"
OUTPUT_BASE="/data/nutriplan_experiments/evaluation_results"
OUTPUT_DIR="${OUTPUT_BASE}/${MODEL_NAME}_seed${SEED}"
PRED_DIR="${OUTPUT_DIR}/predictions"
FINAL_DIR="${OUTPUT_DIR}/final_metrics"

mkdir -p "$PRED_DIR"
mkdir -p "$FINAL_DIR"

echo "========================================================================"
echo "NutriPlan å®Œæ•´è¯„ä¼°æµç¨‹"
echo "========================================================================"
echo "æ¨¡å‹è·¯å¾„: $MODEL_PATH"
echo "æ¨¡å‹åç§°: $MODEL_NAME"
echo "éšæœºç§å­: $SEED"
echo "æ•°æ®ç›®å½•: $DATA_DIR"
echo "è¾“å‡ºç›®å½•: $OUTPUT_DIR"
echo "========================================================================"

# æ¿€æ´»ç¯å¢ƒ
if [ -f ~/miniconda3/etc/profile.d/conda.sh ]; then
    source ~/miniconda3/etc/profile.d/conda.sh
elif [ -f /environment/miniconda3/etc/profile.d/conda.sh ]; then
    source /environment/miniconda3/etc/profile.d/conda.sh
fi
conda activate nutriplan

echo ""
echo "========================================================================"
echo "æ­¥éª¤ 1/3: ç”Ÿæˆæ¨¡å‹é¢„æµ‹"
echo "========================================================================"

# æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡é¢„æµ‹
if [ -f "${PRED_DIR}/predictions.jsonl" ] && [ -f "${PRED_DIR}/references.jsonl" ]; then
    PRED_COUNT=$(wc -l < "${PRED_DIR}/predictions.jsonl")
    echo "âœ“ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„é¢„æµ‹æ–‡ä»¶ ($PRED_COUNT ä¸ªæ ·æœ¬)"
    echo "  è·³è¿‡æ­¥éª¤ 1ï¼Œç›´æ¥è¿›è¡ŒæŒ‡æ ‡è®¡ç®—"
else
    echo "å¼€å§‹ç”Ÿæˆé¢„æµ‹..."

python3 <<PREDICT
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from pathlib import Path
import json
import re
from tqdm import tqdm

model_path = "$MODEL_PATH"
data_dir = Path("$DATA_DIR")
pred_dir = Path("$PRED_DIR")

print(f"åŠ è½½æ¨¡å‹: {model_path}")
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True
)
model.eval()
print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

# åŠ è½½æµ‹è¯•æ•°æ®
test_files = {
    'task_a': 'task_a_test_discriminative.jsonl',
    'task_b': 'task_b_test_from_kg.jsonl',
    'task_c': 'task_c_test_from_kg.jsonl'
}

all_predictions = []
all_references = []
all_constraints = []
all_kg_facts = []

print("\nç”Ÿæˆé¢„æµ‹...")
for task_name, filename in test_files.items():
    filepath = data_dir / filename
    if not filepath.exists():
        print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {filepath}")
        continue

    with open(filepath, 'r', encoding='utf-8') as f:
        samples = [json.loads(line) for line in f if line.strip()]

    # æ¯ä¸ªä»»åŠ¡æœ€å¤šè¯„ä¼°200ä¸ªæ ·æœ¬
    samples = samples[:200]

    # æ‰¹é‡ç”Ÿæˆï¼ˆåŠ é€Ÿ8å€ï¼‰
    batch_size = 8
    num_batches = (len(samples) + batch_size - 1) // batch_size

    for batch_idx in tqdm(range(num_batches), desc=f"å¤„ç† {task_name}"):
        batch_start = batch_idx * batch_size
        batch_end = min(batch_start + batch_size, len(samples))
        batch_samples = samples[batch_start:batch_end]

        # æ‰¹é‡å‡†å¤‡è¾“å…¥
        batch_instructions = [s.get('instruction', '') for s in batch_samples]

        inputs = tokenizer(
            batch_instructions,
            return_tensors="pt",
            truncation=True,
            max_length=512,
            padding=True  # æ‰¹é‡éœ€è¦ padding
        )
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        # æ‰¹é‡ç”Ÿæˆ
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=256,
                do_sample=False,
                temperature=1.0,
                top_p=1.0
            )

        # å¤„ç†æ‰¹é‡è¾“å‡º
        for i, sample in enumerate(batch_samples):
            generated_text = tokenizer.decode(outputs[i], skip_special_tokens=True)

            # ç§»é™¤ instruction é‡å¤éƒ¨åˆ†ï¼ˆæ¨¡å‹å¯èƒ½ä¼šæŠŠ instruction ä¹Ÿè¾“å‡ºï¼‰
            instruction_text = sample.get('instruction', '')
            if generated_text.startswith(instruction_text):
                generated_text = generated_text[len(instruction_text):].strip()

            # å¦‚æœç”Ÿæˆä»¥æ•°å­—å¼€å¤´ï¼Œè¯´æ˜æ˜¯æ­£ç¡®çš„è¾“å‡ºæ ¼å¼
            # å¦åˆ™ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ•°å­—åˆ—è¡¨çš„å¼€å§‹
            import re
            if not re.match(r'^\d+\.', generated_text):
                match = re.search(r'\d+\.\s+\*\*', generated_text)
                if match:
                    generated_text = generated_text[match.start():]

            # å°è¯•è§£æç”Ÿæˆçš„JSONï¼ˆå¦‚æœæ˜¯ç»“æ„åŒ–è¾“å‡ºï¼‰
            try:
                # æå–JSONéƒ¨åˆ†
                if '{' in generated_text and '}' in generated_text:
                    json_start = generated_text.find('{')
                    json_end = generated_text.rfind('}') + 1
                    json_str = generated_text[json_start:json_end]
                    generated_dict = json.loads(json_str)
                else:
                    generated_dict = {'generated': generated_text}
            except:
                generated_dict = {'generated': generated_text}

            # ä¿å­˜
            instruction = sample.get('instruction', '')
            all_predictions.append({
                'task': task_name,
                'instruction': instruction,
                'generated': generated_text,
                **generated_dict
            })

            # å‚è€ƒç­”æ¡ˆ
            reference = sample.get('output', '')
            try:
                if isinstance(reference, str) and reference.startswith('{'):
                    reference_dict = json.loads(reference)
                else:
                    reference_dict = {'output': reference}
            except:
                reference_dict = {'output': reference}

            all_references.append(reference_dict)

            # çº¦æŸ - ä» instruction ä¸­æ™ºèƒ½æå–
            constraints = sample.get('constraints', {})
            if not constraints or constraints == {}:
                # ä» instruction æå–è¥å…»éœ€æ±‚
                constraints = {}
                inst_text = sample.get('instruction', '')

                # æå–èƒ½é‡è¦æ±‚
                energy_match = re.search(r'(\d+)\s*kcal', inst_text)
                if energy_match:
                    constraints['nutrition_targets'] = constraints.get('nutrition_targets', {})
                    constraints['nutrition_targets']['energy'] = int(energy_match.group(1))

                # æå–è›‹ç™½è´¨è¦æ±‚
                protein_match = re.search(r'(\d+)g?\s*protein', inst_text, re.IGNORECASE)
                if protein_match:
                    constraints['nutrition_targets'] = constraints.get('nutrition_targets', {})
                    constraints['nutrition_targets']['protein'] = int(protein_match.group(1))

                # æå–çº¤ç»´è¦æ±‚
                fiber_match = re.search(r'(\d+)g?\s*fiber', inst_text, re.IGNORECASE)
                if fiber_match:
                    constraints['nutrition_targets'] = constraints.get('nutrition_targets', {})
                    constraints['nutrition_targets']['fiber'] = int(fiber_match.group(1))

                # æå–è¿‡æ•åŸ
                if 'allerg' in inst_text.lower() or 'avoid' in inst_text.lower():
                    # ç®€åŒ–ç‰ˆï¼šæ ‡è®°æœ‰è¿‡æ•åŸçº¦æŸ
                    constraints['has_allergen_constraints'] = True

            all_constraints.append(constraints)

            # KGäº‹å® - ä» output ä¸­æå–é£Ÿæåç§°ä½œä¸ºçŸ¥è¯†
            kg_facts = sample.get('kg_facts', [])
            if not kg_facts or kg_facts == []:
                # ä» output æå–é£Ÿæåç§°
                output_text = sample.get('output', '')
                # æå–é£Ÿè°±åç§°ä½œä¸ºçŸ¥è¯†
                recipe_names = re.findall(r'\*\*(.*?)\*\*', output_text)
                if recipe_names:
                    kg_facts = recipe_names[:5]  # æœ€å¤š5ä¸ªé£Ÿè°±åä½œä¸ºçŸ¥è¯†

            all_kg_facts.append(kg_facts if kg_facts else [])

print(f"\nâœ“ ç”Ÿæˆäº† {len(all_predictions)} ä¸ªé¢„æµ‹")

# ä¿å­˜
print("ä¿å­˜é¢„æµ‹ç»“æœ...")
with open(pred_dir / 'predictions.jsonl', 'w', encoding='utf-8') as f:
    for pred in all_predictions:
        f.write(json.dumps(pred, ensure_ascii=False) + '\\n')

with open(pred_dir / 'references.jsonl', 'w', encoding='utf-8') as f:
    for ref in all_references:
        f.write(json.dumps(ref, ensure_ascii=False) + '\\n')

with open(pred_dir / 'constraints.jsonl', 'w', encoding='utf-8') as f:
    for const in all_constraints:
        f.write(json.dumps(const, ensure_ascii=False) + '\\n')

with open(pred_dir / 'kg_facts.jsonl', 'w', encoding='utf-8') as f:
    for facts in all_kg_facts:
        f.write(json.dumps(facts, ensure_ascii=False) + '\\n')

print(f"âœ“ ç»“æœä¿å­˜åˆ°: {pred_dir}")
PREDICT

fi  # ç»“æŸé¢„æµ‹ç”Ÿæˆçš„ if æ£€æŸ¥

echo ""
echo "========================================================================"
echo "æ­¥éª¤ 2/3: è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"
echo "========================================================================"

cd "$(dirname "$0")/.."

python3 evaluation/complete_evaluation.py \
    --predictions "${PRED_DIR}/predictions.jsonl" \
    --references "${PRED_DIR}/references.jsonl" \
    --constraints "${PRED_DIR}/constraints.jsonl" \
    --kg_facts "${PRED_DIR}/kg_facts.jsonl" \
    --output_dir "$FINAL_DIR"

echo ""
echo "========================================================================"
echo "æ­¥éª¤ 3/3: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"
echo "========================================================================"

# åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
cat > "${OUTPUT_DIR}/EVALUATION_SUMMARY.txt" <<SUMMARY
========================================================================
NutriPlan è¯„ä¼°å®Œæ•´æŠ¥å‘Š
========================================================================

æ¨¡å‹ä¿¡æ¯:
  åç§°: $MODEL_NAME
  ç§å­: $SEED
  è·¯å¾„: $MODEL_PATH

è¯„ä¼°æ•°æ®:
  æ•°æ®ç›®å½•: $DATA_DIR
  æ ·æœ¬æ•°é‡: $(wc -l < "${PRED_DIR}/predictions.jsonl")

è¯„ä¼°æŒ‡æ ‡ (å®Œæ•´åˆ—è¡¨):
  âœ“ NutriPlan ç§æœ‰æŒ‡æ ‡: SNCR, UPM, K-Faith, AVC
  âœ“ BLEU ç³»åˆ—: BLEU-1, BLEU-2, BLEU-3, BLEU-4
  âœ“ ROUGE ç³»åˆ—: ROUGE-1, ROUGE-2, ROUGE-L
  âœ“ å…¶ä»–æ ‡å‡†æŒ‡æ ‡: METEOR, BERTScore (P/R/F1)
  âœ“ å¤šæ ·æ€§æŒ‡æ ‡: Dist-1/2/3, Self-BLEU
  âœ“ ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡: Nutrition Accuracy, Ingredient Coverage

ç»“æœæ–‡ä»¶:
  ğŸ“Š èšåˆæŒ‡æ ‡ (JSON):    ${FINAL_DIR}/aggregate_metrics.json
  ğŸ“Š æ¯ä¸ªæ ·æœ¬ (CSV):     ${FINAL_DIR}/per_sample_metrics.csv
  ğŸ“Š è®ºæ–‡è¡¨æ ¼:           ${FINAL_DIR}/paper_table.txt

========================================================================
è¯„ä¼°å®Œæˆæ—¶é—´: $(date)
========================================================================

æŸ¥çœ‹è®ºæ–‡è¡¨æ ¼:
  cat ${FINAL_DIR}/paper_table.txt

æŸ¥çœ‹è¯¦ç»†æŒ‡æ ‡:
  cat ${FINAL_DIR}/aggregate_metrics.json | python3 -m json.tool

========================================================================
SUMMARY

cat "${OUTPUT_DIR}/EVALUATION_SUMMARY.txt"

echo ""
echo "========================================================================"
echo "âœ… å®Œæ•´è¯„ä¼°æµç¨‹å®Œæˆï¼"
echo "========================================================================"
echo ""
echo "ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: $OUTPUT_DIR"
echo ""
echo "ğŸ“Š å…³é”®æ–‡ä»¶:"
echo "   - è®ºæ–‡è¡¨æ ¼:     ${FINAL_DIR}/paper_table.txt"
echo "   - èšåˆæŒ‡æ ‡:     ${FINAL_DIR}/aggregate_metrics.json"
echo "   - æ¯ä¸ªæ ·æœ¬:     ${FINAL_DIR}/per_sample_metrics.csv"
echo "   - è¯„ä¼°æŠ¥å‘Š:     ${OUTPUT_DIR}/EVALUATION_SUMMARY.txt"
echo ""
echo "========================================================================"
